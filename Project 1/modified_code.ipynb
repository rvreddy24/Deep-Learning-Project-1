{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4169204426.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "pip install \n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(7191)\n",
    "\n",
    "# Define the Neural Network class\n",
    "class Neural:\n",
    "\n",
    "    def __init__(self, layers: list, epochs: int,\n",
    "                 learning_rate: float = 0.001, batch_size: int = 32,\n",
    "                 validation_split: float = 0.2, verbose: int = 0):\n",
    "        self._layer_structure = layers\n",
    "        self._batch_size = batch_size\n",
    "        self._epochs = epochs\n",
    "        self._learning_rate = learning_rate\n",
    "        self._validation_split = validation_split\n",
    "        self._verbose = verbose\n",
    "        self._losses = {\"train\": [], \"validation\": []}\n",
    "        self._is_fit = False\n",
    "        self.__layers = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        X, X_val, y, y_val = train_test_split(X, y, test_size=self._validation_split, random_state=42)\n",
    "        self.__layers = self.__init_layers()\n",
    "\n",
    "        for epoch in range(self._epochs):\n",
    "            epoch_losses = []\n",
    "            for i in range(0, len(X), self._batch_size):\n",
    "                x_batch = X[i:i+self._batch_size]\n",
    "                y_batch = y[i:i+self._batch_size]\n",
    "                pred, hidden = self.__forward(x_batch)\n",
    "                loss = self.__calculate_loss(y_batch, pred)\n",
    "                epoch_losses.append(np.mean(loss ** 2))\n",
    "                self.__backward(hidden, loss)\n",
    "\n",
    "            valid_preds, _ = self.__forward(X_val)\n",
    "            train_loss = np.mean(epoch_losses)\n",
    "            valid_loss = np.mean(self.__calculate_mse(valid_preds, y_val))\n",
    "            self._losses[\"train\"].append(train_loss)\n",
    "            self._losses[\"validation\"].append(valid_loss)\n",
    "\n",
    "            if self._verbose:\n",
    "                print(f\"Epoch {epoch}: Train MSE: {train_loss}, Valid MSE: {valid_loss}\")\n",
    "\n",
    "        self._is_fit = True\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        if not self._is_fit:\n",
    "            raise Exception(\"Model has not been trained yet.\")\n",
    "        pred, _ = self.__forward(X)\n",
    "        return pred\n",
    "\n",
    "    def plot_learning(self, config_idx, run_idx):\n",
    "        output_dir = 'learning_curves'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        plt.figure()\n",
    "        plt.plot(self._losses[\"train\"], label=\"Train Loss\")\n",
    "        plt.plot(self._losses[\"validation\"], label=\"Validation Loss\")\n",
    "        plt.title(f\"Learning Curve for Config {config_idx}, Run {run_idx}\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        file_name = f\"learning_curve_config_{config_idx}_run_{run_idx}.png\"\n",
    "        plt.savefig(os.path.join(output_dir, file_name))\n",
    "        plt.close()\n",
    "\n",
    "    def __init_layers(self):\n",
    "        layers = []\n",
    "        for i in range(1, len(self._layer_structure)):\n",
    "            layers.append([\n",
    "                np.random.rand(self._layer_structure[i-1], self._layer_structure[i]) / 5 - .1,\n",
    "                np.ones((1, self._layer_structure[i]))\n",
    "            ])\n",
    "        return layers\n",
    "\n",
    "    def __forward(self, batch: np.ndarray):\n",
    "        hidden = [batch]\n",
    "        for i in range(len(self.__layers)):\n",
    "            batch = np.matmul(batch, self.__layers[i][0]) + self.__layers[i][1]\n",
    "            if i < len(self.__layers) - 1:\n",
    "                batch = np.maximum(batch, 0)\n",
    "            hidden.append(batch)\n",
    "            \n",
    "            # Check for NaN values\n",
    "            if np.isnan(batch).any():\n",
    "                print(f\"NaN detected in layer {i+1}\")\n",
    "                print(f\"Input to this layer: {hidden[i]}\")\n",
    "                print(f\"Weights: {self.__layers[i][0]}\")\n",
    "                print(f\"Biases: {self.__layers[i][1]}\")\n",
    "                raise ValueError(f\"NaN values detected in layer {i+1}\")\n",
    "        \n",
    "        return batch, hidden\n",
    "\n",
    "    def __calculate_loss(self, actual: np.ndarray, predicted: np.ndarray):\n",
    "        return predicted - actual\n",
    "\n",
    "    def __calculate_mse(self, actual: np.ndarray, predicted: np.ndarray):\n",
    "        return (actual - predicted) ** 2\n",
    "\n",
    "    def __backward(self, hidden, grad):\n",
    "        for i in range(len(self.__layers)-1, -1, -1):\n",
    "            if i != len(self.__layers) - 1:\n",
    "                grad = np.multiply(grad, np.heaviside(hidden[i+1], 0))\n",
    "\n",
    "            w_grad = hidden[i].T @ grad\n",
    "            b_grad = np.mean(grad, axis=0)\n",
    "\n",
    "            self.__layers[i][0] -= w_grad * self._learning_rate\n",
    "            self.__layers[i][1] -= b_grad * self._learning_rate\n",
    "\n",
    "            grad = grad @ self.__layers[i][0].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (replace with your actual file path)\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Prepare the dataset\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})  # Assuming 'M' and 'B' are diagnosis values\n",
    "df = df.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "\n",
    "# Select features and target\n",
    "X = df[['radius_mean', 'perimeter_mean', 'area_mean', 'concave points_worst', 'perimeter_worst', 'radius_worst', 'concave points_mean']]\n",
    "y = df['diagnosis']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = y_train.to_numpy().reshape(-1, 1)\n",
    "y_test = y_test.to_numpy().reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Excel file for logging\n",
    "workbook = xlsxwriter.Workbook('results.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Write headers in the Excel file\n",
    "headers = [\"Config\", \"Run\", \"Layer Structure\", \"Learning Rate\", \"Batch Size\", \"Validation Split\", \"Epochs\", \"Test Error\", \"Percent\"]\n",
    "for col, header in enumerate(headers):\n",
    "    worksheet.write(0, col, header)\n",
    "\n",
    "# Configuration list to test\n",
    "configurations = [\n",
    "    {\"layers\": [7, 8, 8, 1], \"learning_rate\": 0.001, \"batch_size\": 32, \"validation_split\": 0.3, \"epochs\": 100},\n",
    "    {\"layers\": [7, 4, 4, 1], \"learning_rate\": 0.0003, \"batch_size\": 64, \"validation_split\": 0.25, \"epochs\": 150},\n",
    "    {\"layers\": [7, 6, 6, 1], \"learning_rate\": 0.001, \"batch_size\": 32, \"validation_split\": 0.15, \"epochs\": 120},\n",
    "    {\"layers\": [7, 10, 5, 1], \"learning_rate\": 0.001, \"batch_size\": 128, \"validation_split\": 0.2, \"epochs\": 200},\n",
    "    {\"layers\": [7, 5, 5, 1], \"learning_rate\": 0.0003, \"batch_size\": 32, \"validation_split\": 0.25, \"epochs\": 200},\n",
    "    {\"layers\": [7, 8, 4, 1], \"learning_rate\": 0.001, \"batch_size\": 64, \"validation_split\": 0.1, \"epochs\": 150},\n",
    "    {\"layers\": [7, 6, 6, 1], \"learning_rate\": 0.001, \"batch_size\": 64, \"validation_split\": 0.3, \"epochs\": 200},\n",
    "    {\"layers\": [7, 8, 8, 1], \"learning_rate\": 0.0003, \"batch_size\": 64, \"validation_split\": 0.25, \"epochs\": 100},\n",
    "    {\"layers\": [7, 10, 10, 1], \"learning_rate\": 0.0003, \"batch_size\": 128, \"validation_split\": 0.3, \"epochs\": 200},\n",
    "    {\"layers\": [7, 4, 4, 1], \"learning_rate\": 0.001, \"batch_size\": 64, \"validation_split\": 0.15, \"epochs\": 100}\n",
    "]\n",
    "\n",
    "# Number of runs per configuration\n",
    "num_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Configuration 1...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 2...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 3...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 4...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 5...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 6...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 7...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 8...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 9...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n",
      "Running Configuration 10...\n",
      "  Run 1...\n",
      "  Run 2...\n",
      "  Run 3...\n",
      "  Run 4...\n",
      "  Run 5...\n"
     ]
    }
   ],
   "source": [
    "# Run each configuration multiple times and log the results\n",
    "row_counter = 1\n",
    "for config_idx, config in enumerate(configurations, start=1):\n",
    "    print(f\"Running Configuration {config_idx}...\")\n",
    "    \n",
    "    for run_idx in range(1, num_runs+1):\n",
    "        print(f\"  Run {run_idx}...\")\n",
    "        \n",
    "        try:\n",
    "            nn = Neural(config[\"layers\"], config[\"epochs\"], config[\"learning_rate\"], config[\"batch_size\"], config[\"validation_split\"], verbose=0)\n",
    "            nn.fit(X_train, y_train)\n",
    "            y_pred = nn.predict(X_test)\n",
    "            \n",
    "            # Check for NaN values in predictions\n",
    "            if np.isnan(y_pred).any():\n",
    "                print(\"NaN values detected in predictions\")\n",
    "                print(f\"Number of NaN values: {np.isnan(y_pred).sum()}\")\n",
    "                print(f\"Prediction shape: {y_pred.shape}\")\n",
    "                raise ValueError(\"NaN values in predictions\")\n",
    "            \n",
    "            test_error = mean_squared_error(y_test, y_pred)\n",
    "            \n",
    "            # Log the results in the Excel sheet\n",
    "            worksheet.write(row_counter, 0, config_idx)\n",
    "            worksheet.write(row_counter, 1, run_idx)\n",
    "            worksheet.write(row_counter, 2, str(config[\"layers\"]))\n",
    "            worksheet.write(row_counter, 3, config[\"learning_rate\"])\n",
    "            worksheet.write(row_counter, 4, config[\"batch_size\"])\n",
    "            worksheet.write(row_counter, 5, config[\"validation_split\"])\n",
    "            worksheet.write(row_counter, 6, config[\"epochs\"])\n",
    "            worksheet.write(row_counter, 7, test_error)\n",
    "            # Calculate and log the Percent\n",
    "            Percent = round(test_error * 100, 2)\n",
    "            worksheet.write(row_counter, 8, Percent)\n",
    "            \n",
    "            row_counter += 1\n",
    "            \n",
    "            # Save the learning curve for this configuration and run\n",
    "            nn.plot_learning(config_idx, run_idx)\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(f\"Error in configuration {config_idx}, run {run_idx}: {str(e)}\")\n",
    "            # Log the error in the Excel sheet\n",
    "            worksheet.write(row_counter, 0, config_idx)\n",
    "            worksheet.write(row_counter, 1, run_idx)\n",
    "            worksheet.write(row_counter, 2, str(config[\"layers\"]))\n",
    "            worksheet.write(row_counter, 3, config[\"learning_rate\"])\n",
    "            worksheet.write(row_counter, 4, config[\"batch_size\"])\n",
    "            worksheet.write(row_counter, 5, config[\"validation_split\"])\n",
    "            worksheet.write(row_counter, 6, config[\"epochs\"])\n",
    "            worksheet.write(row_counter, 7, \"Error: \" + str(e))\n",
    "            row_counter += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error in configuration {config_idx}, run {run_idx}: {str(e)}\")\n",
    "            # Log the error in the Excel sheet\n",
    "            worksheet.write(row_counter, 0, config_idx)\n",
    "            worksheet.write(row_counter, 1, run_idx)\n",
    "            worksheet.write(row_counter, 2, str(config[\"layers\"]))\n",
    "            worksheet.write(row_counter, 3, config[\"learning_rate\"])\n",
    "            worksheet.write(row_counter, 4, config[\"batch_size\"])\n",
    "            worksheet.write(row_counter, 5, config[\"validation_split\"])\n",
    "            worksheet.write(row_counter, 6, config[\"epochs\"])\n",
    "            worksheet.write(row_counter, 7, \"Unexpected Error: \" + str(e))\n",
    "            row_counter += 1\n",
    "\n",
    "# Close the workbook\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
